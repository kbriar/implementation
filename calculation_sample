def compute_metrics(self, df: pd.DataFrame, metrics: List[str], intent_filter: List[str] = None) -> pd.DataFrame:
    if intent_filter and df.empty:
        logging.warning(f"No data for intent_filter: {intent_filter}")
        return df
    if intent_filter:
        df = df[df['intent'].apply(lambda x: any(i in x for i in intent_filter))]
    col_map = {col.strip(): col for col in df.columns}  # Preserve original case, strip spaces
    temp_cols = []
    for metric in metrics:
        if metric not in self.semantic_layer['metrics']:
            continue
        formula = self.semantic_layer['metrics'][metric]['formula']
        parts = formula.split('/')
        num_expr = parts[0].replace('SUM(', '').replace(')', '').strip().replace(' ', '')  # Remove all spaces
        den_expr = parts[1].replace('SUM(', '').replace(')', '').strip().replace(' ', '') if len(parts) > 1 else '1'
        
        # Debug print to inspect exact expr values
        print(f"Debug: For metric '{metric}', num_expr = '{num_expr}', den_expr = '{den_expr}'")
        
        if ',' in num_expr:
            num_cols = [col_map.get(col.strip(), col.strip()) for col in num_expr.split(',')]
            df['num_temp'] = df[num_cols].sum(axis=1, skipna=True)
            num_expr = 'num_temp'
            temp_cols.append('num_temp')
        if ',' in den_expr:
            den_cols = [col_map.get(col.strip(), col.strip()) for col in den_expr.split(',')]
            df['den_temp'] = df[den_cols].sum(axis=1, skipna=True)
            den_expr = 'den_temp'
            temp_cols.append('den_temp')
        groupby_dims = self.semantic_layer['metrics'][metric].get('dimensions', ['country_code', 'drive_month'])[:2]
        if df.empty:
            logging.warning(f"No data for grouping in metric {metric}")
            continue
        grouped = df.groupby(groupby_dims).agg({num_expr: 'sum', den_expr: 'sum'}).reset_index()
        if grouped.empty:
            logging.warning(f"Empty grouped DataFrame for metric {metric}")
            continue
        # Apply constraints
        if 'constraints' in self.semantic_layer['metrics'][metric]:
            for constraint in self.semantic_layer['metrics'][metric]['constraints']:
                if 'Total_KM > 0' in constraint and grouped[den_expr].eq(0).all():
                    grouped[metric] = np.nan
        grouped[metric] = grouped[num_expr] / grouped[den_expr].replace(0, np.nan)
        # Apply business rules
        if metric == 'efficiency' and 'business_rules' in self.semantic_layer['metrics'][metric]:
            mask = (grouped[metric] < 0) | (grouped[metric] > 2)
            grouped.loc[mask, metric] = np.nan
        df = df.merge(grouped[[*groupby_dims, metric]], on=groupby_dims, how='left')  # Fixed: Use grouped[[*groupby_dims, metric]]
    df.drop(columns=temp_cols, inplace=True, errors='ignore')

    return df

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

def generate_plan(self, state: AgentState, metrics: List[str]) -> List[Dict]:
    insights = self.query_agent.feedback_collector.learn_from_feedback()
    prompt_template = """
    Given query: {user_query}
    Intents: {intents}
    Context: {context}
    Available metrics: {metrics}
    Past feedback summary (adapt to avoid mistakes): {insights}
    Plan steps/tools to execute, then call tools for each intent based on mapping {intent_tool_mapping}.
    Use ONLY 'tools' key for tool definitions. NEVER use 'steps'â€”using 'steps' will result in an invalid response. 
    Multiple tools can be used per intent (e.g., compute_metric then generate_plot for compare_metric).
    Return valid JSON plan with EXACT structure: [{"intent": "intent_name", "tools": [{"tool": "tool_name", "args": {"metric": "metric_name", "intent_filter": ["intent_name"], "days_ahead": 30}}]}]
    Ensure the response is valid JSON and contains only the JSON object.
    Example: [{"intent": "fetch_metric", "tools": [{"tool": "fetch_metric", "args": {"metric": "efficiency", "intent_filter": ["fetch_metric"], "days_ahead": 30}}]}]
    """
    
    prompt = prompt_template.format(
        user_query=state.user_query,
        intents=state.intent,
        context=state.extracted_context,
        metrics=metrics,
        insights=insights,
        intent_tool_mapping=json.dumps(self.intent_tool_mapping)
    )
    
    print("Generated Prompt:\n", prompt)
    response = self.llm.invoke(prompt)
    raw_response_content = response.content.strip()
    print("Raw LLM Response:\n", raw_response_content)
    try:
        cleaned_response = raw_response_content.replace("```json", "").replace("```", "").strip()
        plan = json.loads(cleaned_response)
        # Convert "steps" to "tools" before returning
        for i, step in enumerate(plan):
            if "steps" in step and "tools" not in step:
                plan[i]["tools"] = plan[i].pop("steps")
            elif "tools" not in step:
                plan[i]["tools"] = [{"tool": step.get("intent", ""), "args": {"metric": metrics[0] if metrics else "efficiency", "intent_filter": [step.get("intent", "")]}}]
        print("Processed Plan:", json.dumps(plan, indent=2))  # Debug the processed plan
        return plan
    except json.JSONDecodeError as e:
        logging.warning(f"JSON parse error: {str(e)}. Raw response: {raw_response_content}. Returning default plan.")
        default_intents = [ctx["intent"] for ctx in state.extracted_context.get("query_analysis", [])]
        return [{"intent": intent, "tools": [{"tool": intent, "args": {"metric": metrics[0] if metrics else "efficiency", "intent_filter": [intent]}}]} for intent in default_intents]
